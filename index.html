<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Hydra Micro Visualizer</title>
  <style>
    body, html {
      margin: 0; padding: 0; height: 100%;
      background: black;
      overflow: hidden;
      display: flex;
      justify-content: center;
      align-items: center;
    }
    #container {
      position: relative;
      width: 100vw;
      height: 100vh;
      max-width: 100%;
      max-height: 100%;
    }
    canvas {
      width: 100%;
      height: 100%;
      display: block;
    }
    #overlay {
      position: absolute;
      top: 0; left: 0; right: 0; bottom: 0;
      background: rgba(0,0,0,0.4);
      display: flex;
      justify-content: center;
      align-items: center;
      cursor: pointer;
      color: #ccc;
      font-family: sans-serif;
      font-size: 1.5rem;
      user-select: none;
      transition: background 0.3s ease;
      z-index: 10;
    }
    #overlay:hover {
      background: rgba(0,0,0,0.7);
    }
  </style>
</head>
<body>
  <div id="container"></div>
  <div id="overlay">▶️ Activer le micro</div>

  <!-- Librairie Hydra -->
  <script src="https://cdn.jsdelivr.net/npm/hydra-synth/dist/hydra-synth.js"></script>
  <!-- p5 pour audio -->
  <script src="visualizer_p5.min.js"></script>
  <script src="visualizer_p5.sound.min.js"></script>

  <script>
    const overlay = document.getElementById('overlay');
    const container = document.getElementById('container');

    let hydra, mic, fft;
    let audioContextStarted = false;

    // fonction pour lancer audio et hydra
    async function startAudio() {
      if(audioContextStarted) return;
      audioContextStarted = true;

      mic = new p5.AudioIn();
      await mic.start();

      fft = new p5.FFT();
      fft.setInput(mic);

      hydra = new Hydra({
        detectAudio: false,
        canvas: document.createElement('canvas'),
        makeGlobal: false,
        width: container.clientWidth,
        height: container.clientHeight,
      });
      container.appendChild(hydra.canvas);

      hydra.setResolution(container.clientWidth, container.clientHeight);

      // lie le stream micro à hydra
      const audioCtx = getAudioContext();
      const sourceNode = audioCtx.createMediaStreamSource(mic.stream);

      hydra.setSource(sourceNode);

      overlay.style.display = 'none';

      draw();
    }

    function draw() {
      const spectrum = fft.analyze();
      const bass = fft.getEnergy("bass") / 255;

      // Quand le son est trop faible, on fade le visuel
      const alpha = bass < 0.05 ? 0 : 1;

      osc(10, 0.03, 0.8)
        .color(
          0.3 + bass * 1.5,
          0.4 + bass * 1.2,
          0.5 + bass * 1.3
        )
        .rotate(() => Date.now() * 0.00002 + bass * 0.15)
        .modulate(
          osc(5, 0.02)
            .rotate(() => Date.now() * 0.0001 + bass * 0.5),
          0.3
        )
        .kaleid(6)
        .scale(() => 1 + bass * 0.4)
        .blend(o0, 0.25)
        .blend(src(o0).color(0, 0, 0, 1 - alpha), alpha)
        .out();

      requestAnimationFrame(draw);
    }

    // écoute clic overlay pour lancer
    overlay.addEventListener('click', () => {
      startAudio().catch(err => {
        alert('Erreur d\'accès au micro : ' + err.message);
      });
    });

    // resize canvas hydra quand la fenêtre change
    window.addEventListener('resize', () => {
      if(hydra) {
        const w = container.clientWidth;
        const h = container.clientHeight;
        hydra.setResolution(w, h);
        hydra.canvas.style.width = w + 'px';
        hydra.canvas.style.height = h + 'px';
      }
    });

    // utilitaire p5 AudioContext singleton
    function getAudioContext() {
      return window.AudioContext ? new AudioContext() : new webkitAudioContext();
    }
  </script>
</body>
</html>
